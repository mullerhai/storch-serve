// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!

package org.pytorch.serve.grpc.openinference.open_inference_grpc

/** An inference parameter value. The Parameters message describes a 
  * “name”/”value” pair, where the “name” is the name of the parameter
  * and the “value” is a boolean, integer, or string corresponding to 
  * the parameter.
  */
@SerialVersionUID(0L)
final case class InferParameter(
    parameterChoice: org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.Empty,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[InferParameter] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      if (parameterChoice.boolParam.isDefined) {
        val __value = parameterChoice.boolParam.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(1, __value)
      };
      if (parameterChoice.int64Param.isDefined) {
        val __value = parameterChoice.int64Param.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(2, __value)
      };
      if (parameterChoice.stringParam.isDefined) {
        val __value = parameterChoice.stringParam.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(3, __value)
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      parameterChoice.boolParam.foreach { __v =>
        val __m = __v
        _output__.writeBool(1, __m)
      };
      parameterChoice.int64Param.foreach { __v =>
        val __m = __v
        _output__.writeInt64(2, __m)
      };
      parameterChoice.stringParam.foreach { __v =>
        val __m = __v
        _output__.writeString(3, __m)
      };
      unknownFields.writeTo(_output__)
    }
    def getBoolParam: _root_.scala.Boolean = parameterChoice.boolParam.getOrElse(false)
    def withBoolParam(__v: _root_.scala.Boolean): InferParameter = copy(parameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.BoolParam(__v))
    def getInt64Param: _root_.scala.Long = parameterChoice.int64Param.getOrElse(0L)
    def withInt64Param(__v: _root_.scala.Long): InferParameter = copy(parameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.Int64Param(__v))
    def getStringParam: _root_.scala.Predef.String = parameterChoice.stringParam.getOrElse("")
    def withStringParam(__v: _root_.scala.Predef.String): InferParameter = copy(parameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.StringParam(__v))
    def clearParameterChoice: InferParameter = copy(parameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.Empty)
    def withParameterChoice(__v: org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice): InferParameter = copy(parameterChoice = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => parameterChoice.boolParam.orNull
        case 2 => parameterChoice.int64Param.orNull
        case 3 => parameterChoice.stringParam.orNull
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => parameterChoice.boolParam.map(_root_.scalapb.descriptors.PBoolean(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 2 => parameterChoice.int64Param.map(_root_.scalapb.descriptors.PLong(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 3 => parameterChoice.stringParam.map(_root_.scalapb.descriptors.PString(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.type = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter
    // @@protoc_insertion_point(GeneratedMessage[org.pytorch.serve.grpc.openinference.InferParameter])
}

object InferParameter extends scalapb.GeneratedMessageCompanion[org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter = {
    var __parameterChoice: org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.Empty
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __parameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.BoolParam(_input__.readBool())
        case 16 =>
          __parameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.Int64Param(_input__.readInt64())
        case 26 =>
          __parameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.StringParam(_input__.readStringRequireUtf8())
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter(
        parameterChoice = __parameterChoice,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter(
        parameterChoice = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Boolean]]).map(org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.BoolParam(_))
            .orElse[org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice](__fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Long]]).map(org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.Int64Param(_)))
            .orElse[org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice](__fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Predef.String]]).map(org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.StringParam(_)))
            .getOrElse(org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.Empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.pytorch.serve.grpc.openinference.open_inference_grpc.OpenInferenceGrpcProto.javaDescriptor.getMessageTypes().get(12)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.pytorch.serve.grpc.openinference.open_inference_grpc.OpenInferenceGrpcProto.scalaDescriptor.messages(12)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter(
    parameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.Empty
  )
  sealed abstract class ParameterChoice extends _root_.scalapb.GeneratedOneof {
    def isEmpty: _root_.scala.Boolean = false
    def isDefined: _root_.scala.Boolean = true
    def isBoolParam: _root_.scala.Boolean = false
    def isInt64Param: _root_.scala.Boolean = false
    def isStringParam: _root_.scala.Boolean = false
    def boolParam: _root_.scala.Option[_root_.scala.Boolean] = _root_.scala.None
    def int64Param: _root_.scala.Option[_root_.scala.Long] = _root_.scala.None
    def stringParam: _root_.scala.Option[_root_.scala.Predef.String] = _root_.scala.None
  }
  object ParameterChoice {
    @SerialVersionUID(0L)
    case object Empty extends org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice {
      type ValueType = _root_.scala.Nothing
      override def isEmpty: _root_.scala.Boolean = true
      override def isDefined: _root_.scala.Boolean = false
      override def number: _root_.scala.Int = 0
      override def value: _root_.scala.Nothing = throw new java.util.NoSuchElementException("Empty.value")
    }
  
    @SerialVersionUID(0L)
    final case class BoolParam(value: _root_.scala.Boolean) extends org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice {
      type ValueType = _root_.scala.Boolean
      override def isBoolParam: _root_.scala.Boolean = true
      override def boolParam: _root_.scala.Option[_root_.scala.Boolean] = Some(value)
      override def number: _root_.scala.Int = 1
    }
    @SerialVersionUID(0L)
    final case class Int64Param(value: _root_.scala.Long) extends org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice {
      type ValueType = _root_.scala.Long
      override def isInt64Param: _root_.scala.Boolean = true
      override def int64Param: _root_.scala.Option[_root_.scala.Long] = Some(value)
      override def number: _root_.scala.Int = 2
    }
    @SerialVersionUID(0L)
    final case class StringParam(value: _root_.scala.Predef.String) extends org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice {
      type ValueType = _root_.scala.Predef.String
      override def isStringParam: _root_.scala.Boolean = true
      override def stringParam: _root_.scala.Option[_root_.scala.Predef.String] = Some(value)
      override def number: _root_.scala.Int = 3
    }
  }
  implicit class InferParameterLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter](_l) {
    def boolParam: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.getBoolParam)((c_, f_) => c_.copy(parameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.BoolParam(f_)))
    def int64Param: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.getInt64Param)((c_, f_) => c_.copy(parameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.Int64Param(f_)))
    def stringParam: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.getStringParam)((c_, f_) => c_.copy(parameterChoice = org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice.StringParam(f_)))
    def parameterChoice: _root_.scalapb.lenses.Lens[UpperPB, org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice] = field(_.parameterChoice)((c_, f_) => c_.copy(parameterChoice = f_))
  }
  final val BOOL_PARAM_FIELD_NUMBER = 1
  final val INT64_PARAM_FIELD_NUMBER = 2
  final val STRING_PARAM_FIELD_NUMBER = 3
  def of(
    parameterChoice: org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter.ParameterChoice
  ): _root_.org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter = _root_.org.pytorch.serve.grpc.openinference.open_inference_grpc.InferParameter(
    parameterChoice
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[org.pytorch.serve.grpc.openinference.InferParameter])
}
