// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!

package org.pytorch.serve.grpc.inference.inference

/** @param modelName
  *   Name of model.
  *  required
  * @param modelVersion
  *   Version of model to run prediction on.
  *  optional
  * @param input
  *   Input data for model prediction
  *  required
  * @param sequenceId
  *   SequenceId is required for StreamPredictions2 API.
  *  optional
  */
@SerialVersionUID(0L)
final case class PredictionsRequest(
    modelName: _root_.scala.Predef.String = "",
    modelVersion: _root_.scala.Predef.String = "",
    input: _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString] = _root_.scala.collection.immutable.Map.empty,
    sequenceId: _root_.scala.Option[_root_.scala.Predef.String] = _root_.scala.None,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[PredictionsRequest] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = modelName
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
        }
      };
      
      {
        val __value = modelVersion
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(2, __value)
        }
      };
      input.foreach { __item =>
        val __value = org.pytorch.serve.grpc.inference.inference.PredictionsRequest._typemapper_input.toBase(__item)
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      if (sequenceId.isDefined) {
        val __value = sequenceId.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(4, __value)
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = modelName
        if (!__v.isEmpty) {
          _output__.writeString(1, __v)
        }
      };
      {
        val __v = modelVersion
        if (!__v.isEmpty) {
          _output__.writeString(2, __v)
        }
      };
      input.foreach { __v =>
        val __m = org.pytorch.serve.grpc.inference.inference.PredictionsRequest._typemapper_input.toBase(__v)
        _output__.writeTag(3, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      sequenceId.foreach { __v =>
        val __m = __v
        _output__.writeString(4, __m)
      };
      unknownFields.writeTo(_output__)
    }
    def withModelName(__v: _root_.scala.Predef.String): PredictionsRequest = copy(modelName = __v)
    def withModelVersion(__v: _root_.scala.Predef.String): PredictionsRequest = copy(modelVersion = __v)
    def clearInput = copy(input = _root_.scala.collection.immutable.Map.empty)
    def addInput(__vs: (_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString) *): PredictionsRequest = addAllInput(__vs)
    def addAllInput(__vs: Iterable[(_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString)]): PredictionsRequest = copy(input = input ++ __vs)
    def withInput(__v: _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString]): PredictionsRequest = copy(input = __v)
    def getSequenceId: _root_.scala.Predef.String = sequenceId.getOrElse("")
    def clearSequenceId: PredictionsRequest = copy(sequenceId = _root_.scala.None)
    def withSequenceId(__v: _root_.scala.Predef.String): PredictionsRequest = copy(sequenceId = Option(__v))
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = modelName
          if (__t != "") __t else null
        }
        case 2 => {
          val __t = modelVersion
          if (__t != "") __t else null
        }
        case 3 => input.iterator.map(org.pytorch.serve.grpc.inference.inference.PredictionsRequest._typemapper_input.toBase(_)).toSeq
        case 4 => sequenceId.orNull
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PString(modelName)
        case 2 => _root_.scalapb.descriptors.PString(modelVersion)
        case 3 => _root_.scalapb.descriptors.PRepeated(input.iterator.map(org.pytorch.serve.grpc.inference.inference.PredictionsRequest._typemapper_input.toBase(_).toPMessage).toVector)
        case 4 => sequenceId.map(_root_.scalapb.descriptors.PString(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: org.pytorch.serve.grpc.inference.inference.PredictionsRequest.type = org.pytorch.serve.grpc.inference.inference.PredictionsRequest
    // @@protoc_insertion_point(GeneratedMessage[org.pytorch.serve.grpc.inference.PredictionsRequest])
}

object PredictionsRequest extends scalapb.GeneratedMessageCompanion[org.pytorch.serve.grpc.inference.inference.PredictionsRequest] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.pytorch.serve.grpc.inference.inference.PredictionsRequest] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.pytorch.serve.grpc.inference.inference.PredictionsRequest = {
    var __modelName: _root_.scala.Predef.String = ""
    var __modelVersion: _root_.scala.Predef.String = ""
    val __input: _root_.scala.collection.mutable.Builder[(_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString), _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString]] = _root_.scala.collection.immutable.Map.newBuilder[_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString]
    var __sequenceId: _root_.scala.Option[_root_.scala.Predef.String] = _root_.scala.None
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __modelName = _input__.readStringRequireUtf8()
        case 18 =>
          __modelVersion = _input__.readStringRequireUtf8()
        case 26 =>
          __input += org.pytorch.serve.grpc.inference.inference.PredictionsRequest._typemapper_input.toCustom(_root_.scalapb.LiteParser.readMessage[org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry](_input__))
        case 34 =>
          __sequenceId = _root_.scala.Option(_input__.readStringRequireUtf8())
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    org.pytorch.serve.grpc.inference.inference.PredictionsRequest(
        modelName = __modelName,
        modelVersion = __modelVersion,
        input = __input.result(),
        sequenceId = __sequenceId,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[org.pytorch.serve.grpc.inference.inference.PredictionsRequest] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      org.pytorch.serve.grpc.inference.inference.PredictionsRequest(
        modelName = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        modelVersion = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        input = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Seq[org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry]]).getOrElse(_root_.scala.Seq.empty).iterator.map(org.pytorch.serve.grpc.inference.inference.PredictionsRequest._typemapper_input.toCustom(_)).toMap,
        sequenceId = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Predef.String]])
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.pytorch.serve.grpc.inference.inference.InferenceProto.javaDescriptor.getMessageTypes().get(0)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.pytorch.serve.grpc.inference.inference.InferenceProto.scalaDescriptor.messages(0)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[?] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[?] = null
    (__number: @_root_.scala.unchecked) match {
      case 3 => __out = org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]] =
    Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]](
      _root_.org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry
    )
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[?] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = org.pytorch.serve.grpc.inference.inference.PredictionsRequest(
    modelName = "",
    modelVersion = "",
    input = _root_.scala.collection.immutable.Map.empty,
    sequenceId = _root_.scala.None
  )
  @SerialVersionUID(0L)
  final case class InputEntry(
      key: _root_.scala.Predef.String = "",
      value: _root_.com.google.protobuf.ByteString = _root_.com.google.protobuf.ByteString.EMPTY,
      unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
      ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[InputEntry] {
      @transient
      private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
      private[this] def __computeSerializedSize(): _root_.scala.Int = {
        var __size = 0
        
        {
          val __value = key
          if (!__value.isEmpty) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
          }
        };
        
        {
          val __value = value
          if (!__value.isEmpty) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeBytesSize(2, __value)
          }
        };
        __size += unknownFields.serializedSize
        __size
      }
      override def serializedSize: _root_.scala.Int = {
        var __size = __serializedSizeMemoized
        if (__size == 0) {
          __size = __computeSerializedSize() + 1
          __serializedSizeMemoized = __size
        }
        __size - 1
        
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        {
          val __v = key
          if (!__v.isEmpty) {
            _output__.writeString(1, __v)
          }
        };
        {
          val __v = value
          if (!__v.isEmpty) {
            _output__.writeBytes(2, __v)
          }
        };
        unknownFields.writeTo(_output__)
      }
      def withKey(__v: _root_.scala.Predef.String): InputEntry = copy(key = __v)
      def withValue(__v: _root_.com.google.protobuf.ByteString): InputEntry = copy(value = __v)
      def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
      def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => {
            val __t = key
            if (__t != "") __t else null
          }
          case 2 => {
            val __t = value
            if (__t != _root_.com.google.protobuf.ByteString.EMPTY) __t else null
          }
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => _root_.scalapb.descriptors.PString(key)
          case 2 => _root_.scalapb.descriptors.PByteString(value)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion: org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry.type = org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry
      // @@protoc_insertion_point(GeneratedMessage[org.pytorch.serve.grpc.inference.PredictionsRequest.InputEntry])
  }
  
  object InputEntry extends scalapb.GeneratedMessageCompanion[org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry] = this
    def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry = {
      var __key: _root_.scala.Predef.String = ""
      var __value: _root_.com.google.protobuf.ByteString = _root_.com.google.protobuf.ByteString.EMPTY
      var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 10 =>
            __key = _input__.readStringRequireUtf8()
          case 18 =>
            __value = _input__.readBytes()
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry(
          key = __key,
          value = __value,
          unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
        org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry(
          key = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
          value = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.com.google.protobuf.ByteString]).getOrElse(_root_.com.google.protobuf.ByteString.EMPTY)
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.pytorch.serve.grpc.inference.inference.PredictionsRequest.javaDescriptor.getNestedTypes().get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.pytorch.serve.grpc.inference.inference.PredictionsRequest.scalaDescriptor.nestedMessages(0)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[?] = throw new MatchError(__number)
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]] = Seq.empty
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[?] = throw new MatchError(__fieldNumber)
    lazy val defaultInstance = org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry(
      key = "",
      value = _root_.com.google.protobuf.ByteString.EMPTY
    )
    implicit class InputEntryLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry](_l) {
      def key: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.key)((c_, f_) => c_.copy(key = f_))
      def value: _root_.scalapb.lenses.Lens[UpperPB, _root_.com.google.protobuf.ByteString] = field(_.value)((c_, f_) => c_.copy(value = f_))
    }
    final val KEY_FIELD_NUMBER = 1
    final val VALUE_FIELD_NUMBER = 2
    @transient
    implicit val keyValueMapper: _root_.scalapb.TypeMapper[org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry, (_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString)] =
      _root_.scalapb.TypeMapper[org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry, (_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString)](__m => (__m.key, __m.value))(__p => org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry(__p._1, __p._2))
    def of(
      key: _root_.scala.Predef.String,
      value: _root_.com.google.protobuf.ByteString
    ): _root_.org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry = _root_.org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry(
      key,
      value
    )
    // @@protoc_insertion_point(GeneratedMessageCompanion[org.pytorch.serve.grpc.inference.PredictionsRequest.InputEntry])
  }
  
  implicit class PredictionsRequestLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.pytorch.serve.grpc.inference.inference.PredictionsRequest]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.pytorch.serve.grpc.inference.inference.PredictionsRequest](_l) {
    def modelName: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.modelName)((c_, f_) => c_.copy(modelName = f_))
    def modelVersion: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.modelVersion)((c_, f_) => c_.copy(modelVersion = f_))
    def input: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString]] = field(_.input)((c_, f_) => c_.copy(input = f_))
    def sequenceId: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.getSequenceId)((c_, f_) => c_.copy(sequenceId = _root_.scala.Option(f_)))
    def optionalSequenceId: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[_root_.scala.Predef.String]] = field(_.sequenceId)((c_, f_) => c_.copy(sequenceId = f_))
  }
  final val MODEL_NAME_FIELD_NUMBER = 1
  final val MODEL_VERSION_FIELD_NUMBER = 2
  final val INPUT_FIELD_NUMBER = 3
  final val SEQUENCE_ID_FIELD_NUMBER = 4
  @transient
  private[inference] val _typemapper_input: _root_.scalapb.TypeMapper[org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry, (_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString)] = implicitly[_root_.scalapb.TypeMapper[org.pytorch.serve.grpc.inference.inference.PredictionsRequest.InputEntry, (_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString)]]
  def of(
    modelName: _root_.scala.Predef.String,
    modelVersion: _root_.scala.Predef.String,
    input: _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, _root_.com.google.protobuf.ByteString],
    sequenceId: _root_.scala.Option[_root_.scala.Predef.String]
  ): _root_.org.pytorch.serve.grpc.inference.inference.PredictionsRequest = _root_.org.pytorch.serve.grpc.inference.inference.PredictionsRequest(
    modelName,
    modelVersion,
    input,
    sequenceId
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[org.pytorch.serve.grpc.inference.PredictionsRequest])
}
