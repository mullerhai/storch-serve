// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!

package org.pytorch.serve.grpc.inference.inference

/** @param prediction
  *   Response content for prediction
  * @param sequenceId
  *   SequenceId is required for StreamPredictions2 API.
  *  optional
  * @param status
  *   Error information for StreamPredictions2 API.
  *  optional
  */
@SerialVersionUID(0L)
final case class PredictionResponse(
    prediction: _root_.com.google.protobuf.ByteString = _root_.com.google.protobuf.ByteString.EMPTY,
    sequenceId: _root_.scala.Option[_root_.scala.Predef.String] = _root_.scala.None,
    status: _root_.scala.Option[com.google.rpc.status.Status] = _root_.scala.None,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[PredictionResponse] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = prediction
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBytesSize(1, __value)
        }
      };
      if (sequenceId.isDefined) {
        val __value = sequenceId.get
        __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(2, __value)
      };
      if (status.isDefined) {
        val __value = status.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = prediction
        if (!__v.isEmpty) {
          _output__.writeBytes(1, __v)
        }
      };
      sequenceId.foreach { __v =>
        val __m = __v
        _output__.writeString(2, __m)
      };
      status.foreach { __v =>
        val __m = __v
        _output__.writeTag(3, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      unknownFields.writeTo(_output__)
    }
    def withPrediction(__v: _root_.com.google.protobuf.ByteString): PredictionResponse = copy(prediction = __v)
    def getSequenceId: _root_.scala.Predef.String = sequenceId.getOrElse("")
    def clearSequenceId: PredictionResponse = copy(sequenceId = _root_.scala.None)
    def withSequenceId(__v: _root_.scala.Predef.String): PredictionResponse = copy(sequenceId = Option(__v))
    def getStatus: com.google.rpc.status.Status = status.getOrElse(com.google.rpc.status.Status.defaultInstance)
    def clearStatus: PredictionResponse = copy(status = _root_.scala.None)
    def withStatus(__v: com.google.rpc.status.Status): PredictionResponse = copy(status = Option(__v))
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = prediction
          if (__t != _root_.com.google.protobuf.ByteString.EMPTY) __t else null
        }
        case 2 => sequenceId.orNull
        case 3 => status.orNull
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PByteString(prediction)
        case 2 => sequenceId.map(_root_.scalapb.descriptors.PString(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 3 => status.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: org.pytorch.serve.grpc.inference.inference.PredictionResponse.type = org.pytorch.serve.grpc.inference.inference.PredictionResponse
    // @@protoc_insertion_point(GeneratedMessage[org.pytorch.serve.grpc.inference.PredictionResponse])
}

object PredictionResponse extends scalapb.GeneratedMessageCompanion[org.pytorch.serve.grpc.inference.inference.PredictionResponse] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.pytorch.serve.grpc.inference.inference.PredictionResponse] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.pytorch.serve.grpc.inference.inference.PredictionResponse = {
    var __prediction: _root_.com.google.protobuf.ByteString = _root_.com.google.protobuf.ByteString.EMPTY
    var __sequenceId: _root_.scala.Option[_root_.scala.Predef.String] = _root_.scala.None
    var __status: _root_.scala.Option[com.google.rpc.status.Status] = _root_.scala.None
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __prediction = _input__.readBytes()
        case 18 =>
          __sequenceId = _root_.scala.Option(_input__.readStringRequireUtf8())
        case 26 =>
          __status = _root_.scala.Option(__status.fold(_root_.scalapb.LiteParser.readMessage[com.google.rpc.status.Status](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    org.pytorch.serve.grpc.inference.inference.PredictionResponse(
        prediction = __prediction,
        sequenceId = __sequenceId,
        status = __status,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[org.pytorch.serve.grpc.inference.inference.PredictionResponse] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      org.pytorch.serve.grpc.inference.inference.PredictionResponse(
        prediction = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.com.google.protobuf.ByteString]).getOrElse(_root_.com.google.protobuf.ByteString.EMPTY),
        sequenceId = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Predef.String]]),
        status = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).flatMap(_.as[_root_.scala.Option[com.google.rpc.status.Status]])
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.pytorch.serve.grpc.inference.inference.InferenceProto.javaDescriptor.getMessageTypes().get(1)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.pytorch.serve.grpc.inference.inference.InferenceProto.scalaDescriptor.messages(1)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 3 => __out = com.google.rpc.status.Status
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = org.pytorch.serve.grpc.inference.inference.PredictionResponse(
    prediction = _root_.com.google.protobuf.ByteString.EMPTY,
    sequenceId = _root_.scala.None,
    status = _root_.scala.None
  )
  implicit class PredictionResponseLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.pytorch.serve.grpc.inference.inference.PredictionResponse]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.pytorch.serve.grpc.inference.inference.PredictionResponse](_l) {
    def prediction: _root_.scalapb.lenses.Lens[UpperPB, _root_.com.google.protobuf.ByteString] = field(_.prediction)((c_, f_) => c_.copy(prediction = f_))
    def sequenceId: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.getSequenceId)((c_, f_) => c_.copy(sequenceId = _root_.scala.Option(f_)))
    def optionalSequenceId: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[_root_.scala.Predef.String]] = field(_.sequenceId)((c_, f_) => c_.copy(sequenceId = f_))
    def status: _root_.scalapb.lenses.Lens[UpperPB, com.google.rpc.status.Status] = field(_.getStatus)((c_, f_) => c_.copy(status = _root_.scala.Option(f_)))
    def optionalStatus: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[com.google.rpc.status.Status]] = field(_.status)((c_, f_) => c_.copy(status = f_))
  }
  final val PREDICTION_FIELD_NUMBER = 1
  final val SEQUENCE_ID_FIELD_NUMBER = 2
  final val STATUS_FIELD_NUMBER = 3
  def of(
    prediction: _root_.com.google.protobuf.ByteString,
    sequenceId: _root_.scala.Option[_root_.scala.Predef.String],
    status: _root_.scala.Option[com.google.rpc.status.Status]
  ): _root_.org.pytorch.serve.grpc.inference.inference.PredictionResponse = _root_.org.pytorch.serve.grpc.inference.inference.PredictionResponse(
    prediction,
    sequenceId,
    status
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[org.pytorch.serve.grpc.inference.PredictionResponse])
}
