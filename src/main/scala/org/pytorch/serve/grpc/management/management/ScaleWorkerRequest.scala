// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!

package org.pytorch.serve.grpc.management.management

/** @param modelName
  *   Name of model to scale workers.
  *  required
  * @param modelVersion
  *   Model version.
  *  optional
  * @param maxWorker
  *   Maximum number of worker processes.
  *  optional
  * @param minWorker
  *   Minimum number of worker processes.
  *  optional
  * @param numberGpu
  *   Number of GPU worker processes to create.
  *  optional
  * @param synchronous
  *   Decides whether the call is synchronous or not, default: false.
  *  optional
  * @param timeout
  *   Waiting up to the specified wait time if necessary for a worker to complete all pending requests. Use 0 to terminate backend worker process immediately. Use -1 for wait infinitely.
  *  optional
  */
@SerialVersionUID(0L)
final case class ScaleWorkerRequest(
    modelName: _root_.scala.Predef.String = "",
    modelVersion: _root_.scala.Predef.String = "",
    maxWorker: _root_.scala.Int = 0,
    minWorker: _root_.scala.Int = 0,
    numberGpu: _root_.scala.Int = 0,
    synchronous: _root_.scala.Boolean = false,
    timeout: _root_.scala.Int = 0,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[ScaleWorkerRequest] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = modelName
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
        }
      };
      
      {
        val __value = modelVersion
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(2, __value)
        }
      };
      
      {
        val __value = maxWorker
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(3, __value)
        }
      };
      
      {
        val __value = minWorker
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(4, __value)
        }
      };
      
      {
        val __value = numberGpu
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(5, __value)
        }
      };
      
      {
        val __value = synchronous
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(6, __value)
        }
      };
      
      {
        val __value = timeout
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(7, __value)
        }
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = modelName
        if (!__v.isEmpty) {
          _output__.writeString(1, __v)
        }
      };
      {
        val __v = modelVersion
        if (!__v.isEmpty) {
          _output__.writeString(2, __v)
        }
      };
      {
        val __v = maxWorker
        if (__v != 0) {
          _output__.writeInt32(3, __v)
        }
      };
      {
        val __v = minWorker
        if (__v != 0) {
          _output__.writeInt32(4, __v)
        }
      };
      {
        val __v = numberGpu
        if (__v != 0) {
          _output__.writeInt32(5, __v)
        }
      };
      {
        val __v = synchronous
        if (__v != false) {
          _output__.writeBool(6, __v)
        }
      };
      {
        val __v = timeout
        if (__v != 0) {
          _output__.writeInt32(7, __v)
        }
      };
      unknownFields.writeTo(_output__)
    }
    def withModelName(__v: _root_.scala.Predef.String): ScaleWorkerRequest = copy(modelName = __v)
    def withModelVersion(__v: _root_.scala.Predef.String): ScaleWorkerRequest = copy(modelVersion = __v)
    def withMaxWorker(__v: _root_.scala.Int): ScaleWorkerRequest = copy(maxWorker = __v)
    def withMinWorker(__v: _root_.scala.Int): ScaleWorkerRequest = copy(minWorker = __v)
    def withNumberGpu(__v: _root_.scala.Int): ScaleWorkerRequest = copy(numberGpu = __v)
    def withSynchronous(__v: _root_.scala.Boolean): ScaleWorkerRequest = copy(synchronous = __v)
    def withTimeout(__v: _root_.scala.Int): ScaleWorkerRequest = copy(timeout = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = modelName
          if (__t != "") __t else null
        }
        case 2 => {
          val __t = modelVersion
          if (__t != "") __t else null
        }
        case 3 => {
          val __t = maxWorker
          if (__t != 0) __t else null
        }
        case 4 => {
          val __t = minWorker
          if (__t != 0) __t else null
        }
        case 5 => {
          val __t = numberGpu
          if (__t != 0) __t else null
        }
        case 6 => {
          val __t = synchronous
          if (__t != false) __t else null
        }
        case 7 => {
          val __t = timeout
          if (__t != 0) __t else null
        }
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PString(modelName)
        case 2 => _root_.scalapb.descriptors.PString(modelVersion)
        case 3 => _root_.scalapb.descriptors.PInt(maxWorker)
        case 4 => _root_.scalapb.descriptors.PInt(minWorker)
        case 5 => _root_.scalapb.descriptors.PInt(numberGpu)
        case 6 => _root_.scalapb.descriptors.PBoolean(synchronous)
        case 7 => _root_.scalapb.descriptors.PInt(timeout)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: org.pytorch.serve.grpc.management.management.ScaleWorkerRequest.type = org.pytorch.serve.grpc.management.management.ScaleWorkerRequest
    // @@protoc_insertion_point(GeneratedMessage[org.pytorch.serve.grpc.management.ScaleWorkerRequest])
}

object ScaleWorkerRequest extends scalapb.GeneratedMessageCompanion[org.pytorch.serve.grpc.management.management.ScaleWorkerRequest] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.pytorch.serve.grpc.management.management.ScaleWorkerRequest] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.pytorch.serve.grpc.management.management.ScaleWorkerRequest = {
    var __modelName: _root_.scala.Predef.String = ""
    var __modelVersion: _root_.scala.Predef.String = ""
    var __maxWorker: _root_.scala.Int = 0
    var __minWorker: _root_.scala.Int = 0
    var __numberGpu: _root_.scala.Int = 0
    var __synchronous: _root_.scala.Boolean = false
    var __timeout: _root_.scala.Int = 0
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __modelName = _input__.readStringRequireUtf8()
        case 18 =>
          __modelVersion = _input__.readStringRequireUtf8()
        case 24 =>
          __maxWorker = _input__.readInt32()
        case 32 =>
          __minWorker = _input__.readInt32()
        case 40 =>
          __numberGpu = _input__.readInt32()
        case 48 =>
          __synchronous = _input__.readBool()
        case 56 =>
          __timeout = _input__.readInt32()
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    org.pytorch.serve.grpc.management.management.ScaleWorkerRequest(
        modelName = __modelName,
        modelVersion = __modelVersion,
        maxWorker = __maxWorker,
        minWorker = __minWorker,
        numberGpu = __numberGpu,
        synchronous = __synchronous,
        timeout = __timeout,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[org.pytorch.serve.grpc.management.management.ScaleWorkerRequest] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      org.pytorch.serve.grpc.management.management.ScaleWorkerRequest(
        modelName = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        modelVersion = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        maxWorker = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        minWorker = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        numberGpu = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        synchronous = __fieldsMap.get(scalaDescriptor.findFieldByNumber(6).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
        timeout = __fieldsMap.get(scalaDescriptor.findFieldByNumber(7).get).map(_.as[_root_.scala.Int]).getOrElse(0)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.pytorch.serve.grpc.management.management.ManagementProto.javaDescriptor.getMessageTypes().get(4)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.pytorch.serve.grpc.management.management.ManagementProto.scalaDescriptor.messages(4)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = org.pytorch.serve.grpc.management.management.ScaleWorkerRequest(
    modelName = "",
    modelVersion = "",
    maxWorker = 0,
    minWorker = 0,
    numberGpu = 0,
    synchronous = false,
    timeout = 0
  )
  implicit class ScaleWorkerRequestLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.pytorch.serve.grpc.management.management.ScaleWorkerRequest]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.pytorch.serve.grpc.management.management.ScaleWorkerRequest](_l) {
    def modelName: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.modelName)((c_, f_) => c_.copy(modelName = f_))
    def modelVersion: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.modelVersion)((c_, f_) => c_.copy(modelVersion = f_))
    def maxWorker: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.maxWorker)((c_, f_) => c_.copy(maxWorker = f_))
    def minWorker: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.minWorker)((c_, f_) => c_.copy(minWorker = f_))
    def numberGpu: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.numberGpu)((c_, f_) => c_.copy(numberGpu = f_))
    def synchronous: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.synchronous)((c_, f_) => c_.copy(synchronous = f_))
    def timeout: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.timeout)((c_, f_) => c_.copy(timeout = f_))
  }
  final val MODEL_NAME_FIELD_NUMBER = 1
  final val MODEL_VERSION_FIELD_NUMBER = 2
  final val MAX_WORKER_FIELD_NUMBER = 3
  final val MIN_WORKER_FIELD_NUMBER = 4
  final val NUMBER_GPU_FIELD_NUMBER = 5
  final val SYNCHRONOUS_FIELD_NUMBER = 6
  final val TIMEOUT_FIELD_NUMBER = 7
  def of(
    modelName: _root_.scala.Predef.String,
    modelVersion: _root_.scala.Predef.String,
    maxWorker: _root_.scala.Int,
    minWorker: _root_.scala.Int,
    numberGpu: _root_.scala.Int,
    synchronous: _root_.scala.Boolean,
    timeout: _root_.scala.Int
  ): _root_.org.pytorch.serve.grpc.management.management.ScaleWorkerRequest = _root_.org.pytorch.serve.grpc.management.management.ScaleWorkerRequest(
    modelName,
    modelVersion,
    maxWorker,
    minWorker,
    numberGpu,
    synchronous,
    timeout
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[org.pytorch.serve.grpc.management.ScaleWorkerRequest])
}
