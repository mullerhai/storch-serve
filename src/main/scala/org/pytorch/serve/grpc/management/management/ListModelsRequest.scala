// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!

package org.pytorch.serve.grpc.management.management

/** @param limit
  *   Use this parameter to specify the maximum number of items to return. When this value is present, TorchServe does not return more than the specified number of items, but it might return fewer. This value is optional. If you include a value, it must be between 1 and 1000, inclusive. If you do not include a value, it defaults to 100.
  *  optional
  * @param nextPageToken
  *   The token to retrieve the next set of results. TorchServe provides the token when the response from a previous call has more results than the maximum page size.
  *  optional
  */
@SerialVersionUID(0L)
final case class ListModelsRequest(
    limit: _root_.scala.Int = 0,
    nextPageToken: _root_.scala.Int = 0,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[ListModelsRequest] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = limit
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
        }
      };
      
      {
        val __value = nextPageToken
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(2, __value)
        }
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = limit
        if (__v != 0) {
          _output__.writeInt32(1, __v)
        }
      };
      {
        val __v = nextPageToken
        if (__v != 0) {
          _output__.writeInt32(2, __v)
        }
      };
      unknownFields.writeTo(_output__)
    }
    def withLimit(__v: _root_.scala.Int): ListModelsRequest = copy(limit = __v)
    def withNextPageToken(__v: _root_.scala.Int): ListModelsRequest = copy(nextPageToken = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = limit
          if (__t != 0) __t else null
        }
        case 2 => {
          val __t = nextPageToken
          if (__t != 0) __t else null
        }
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PInt(limit)
        case 2 => _root_.scalapb.descriptors.PInt(nextPageToken)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: org.pytorch.serve.grpc.management.management.ListModelsRequest.type = org.pytorch.serve.grpc.management.management.ListModelsRequest
    // @@protoc_insertion_point(GeneratedMessage[org.pytorch.serve.grpc.management.ListModelsRequest])
}

object ListModelsRequest extends scalapb.GeneratedMessageCompanion[org.pytorch.serve.grpc.management.management.ListModelsRequest] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.pytorch.serve.grpc.management.management.ListModelsRequest] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.pytorch.serve.grpc.management.management.ListModelsRequest = {
    var __limit: _root_.scala.Int = 0
    var __nextPageToken: _root_.scala.Int = 0
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __limit = _input__.readInt32()
        case 16 =>
          __nextPageToken = _input__.readInt32()
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    org.pytorch.serve.grpc.management.management.ListModelsRequest(
        limit = __limit,
        nextPageToken = __nextPageToken,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[org.pytorch.serve.grpc.management.management.ListModelsRequest] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      org.pytorch.serve.grpc.management.management.ListModelsRequest(
        limit = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        nextPageToken = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Int]).getOrElse(0)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.pytorch.serve.grpc.management.management.ManagementProto.javaDescriptor.getMessageTypes().get(2)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.pytorch.serve.grpc.management.management.ManagementProto.scalaDescriptor.messages(2)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[?] = throw new MatchError(__number)
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[?] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = org.pytorch.serve.grpc.management.management.ListModelsRequest(
    limit = 0,
    nextPageToken = 0
  )
  implicit class ListModelsRequestLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.pytorch.serve.grpc.management.management.ListModelsRequest]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.pytorch.serve.grpc.management.management.ListModelsRequest](_l) {
    def limit: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.limit)((c_, f_) => c_.copy(limit = f_))
    def nextPageToken: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.nextPageToken)((c_, f_) => c_.copy(nextPageToken = f_))
  }
  final val LIMIT_FIELD_NUMBER = 1
  final val NEXT_PAGE_TOKEN_FIELD_NUMBER = 2
  def of(
    limit: _root_.scala.Int,
    nextPageToken: _root_.scala.Int
  ): _root_.org.pytorch.serve.grpc.management.management.ListModelsRequest = _root_.org.pytorch.serve.grpc.management.management.ListModelsRequest(
    limit,
    nextPageToken
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[org.pytorch.serve.grpc.management.ListModelsRequest])
}
